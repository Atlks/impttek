1）首先，数据挖掘－Data Mining不是一个骗局，而是一种还处于发展中，已经投入部分投入实际生产实践的技术框架。DM之所以经常和知识发现概念相关联是因为知识发现（Knowledge Discovery）是DM的目标和产出（output）。随着信息化应用的普及，传统的交易性数据（Transaction），会在现有的数据库系统中存储下来，随着时间的累计，这种数据变得海量。面对这些海量数据，这其中是否存在一些可以更好帮助决策的东西。


2）数据（Data）-信息（information）-知识（Knowledge）是一个递进的关系。数据的电子化产生了信息，比如：我们可以通过SQL语句检索到我们要的信息，但是我们无法用简单的SQL语句找到我们需要的知识，


3）数据挖掘的步骤一般可以分为：数据提取（ETL）－数据仓库－数据挖掘工具－知识发现。





 


1、情感分析：从xxxx上观察到用户对某一事物或者观点是怎么评价的，而且还能基于这些说法见解采取行动。目前好像只能从计算词汇数量上去理解理解在博客和社交网站上发帖人背后的情感是什么，目前为止确定每个消息的情绪是积极的还是消极的技术尚未成熟


3、偏好分析：可以根据用户的共同特征（偏好），通过算法进行数据挖掘，以便对客户群进行分群操作（可以从各个方面各个角度进行分群）。


可以对某些特定事件如生日等进行推荐或营销


事件雷达分析： 。异常事件解析...

事件的相关性:
为什么所以什么？现在我们不强调这个问题，我们只知道这是相关的，发生A事件之后就发生B事件，但是这两者是什么关系，我们不清楚。把相关事件打在一起，发生A事件之后，B事件点击率会高，但是因果关系不怎么追求了，但是肯定是有关系的。我个人感受非常深的，在今天开放的数据，隐私问题，很多情况是能避免的，越来越多开放的社区出现了。你使用一个产品，你使用微博


第一个就是推荐系统。一个人上来以后，你给他推荐感兴趣的人，他的朋友。一种是基于兴趣，一种是基于关系的。你只有让他形成更强的关系链，就是他的好朋友，形成更好的兴趣，感情，交集圈。推荐系统和广告推荐是很相似的，算法做法是一样的。


第三个叫微热点，真正实现信息关联。微博里面每时每刻都有热点事情发生，用机器发现哪些热点事件能读出来。它要做的事很多，第一发现热点事情，第二把热点事情聚在一起形成热点事件的脉络，第三把热点事件投放到用户面前，是纯自动的形式。每天数亿的数据怎么把它挑选出来。



第五个是微博管家。怎么样把好的东西挑出来，垃圾自动过滤。我们邮箱就有垃圾箱，微博也有人做吗？不这么做有很多原因，一是技术是不是准确，二是商业化的问题。我相信不愿意做的原因就是商业化的问题。商业化的价值怎么做，这是需要我们做的，把垃圾信息过滤掉。



根据前后关系--文本分类
微频道刚才提到了，对优势内容的挑选。单纯从技术角度来考虑这个问题，文本分类是很难的事，因为文本很短，还要分类，不像一些文章，几百个字进行分类，你有充足的理由做这个事，这里面需要很多办法，你不能把精力都放在文本本身，还有用户呢。这个用户老发财经类的内容，他发文章的时候，财经概率很多。利用这种思维，用更多的特征来学习，不要局限在内容本身里面准确会大幅提升。分完类之后还要把差的质量去掉，把好的质量选出来。比如说展示量，各种各样的东西，都是帮助你学习的


对内容质量的判断



包括用户和用户之间的关系，内容和内容之间的关系，用户和内容之间的关系。